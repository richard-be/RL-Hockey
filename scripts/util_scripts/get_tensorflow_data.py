# NOTE: this code was generated by ChatGPT and is only used to extract the scalar data from the tensorboard logs. 

import tensorflow as tf
import matplotlib.pyplot as plt

import os
import pandas as pd
from tensorboard.backend.event_processing import event_accumulator
from tqdm import tqdm

def save_scalar_data(path, output_dir, skip_existing=True):
    if skip_existing and os.path.exists(output_dir) and len(os.listdir(output_dir)) > 0:
        print(f"Output directory {output_dir} already exists, skipping.")
        return
    
    ea = event_accumulator.EventAccumulator(path)
    ea.Reload()

    # Get all scalar tags
    scalar_tags = ea.Tags()['scalars']

    for tag in scalar_tags:

        events = ea.Scalars(tag)
        
        df = pd.DataFrame({
            "step": [e.step for e in events],
            "value": [e.value for e in events],
            "wall_time": [e.wall_time for e in events],
        })
        
        # sanitize tag name for filename
        filename = tag.replace("/", "-") + ".csv"
        
        df.to_csv(os.path.join(output_dir, filename), index=False)


log_dir = "./runs/td3/HockeyOne-v0/"
output_dir = "./data/td3/HockeyOne-v0/"
skip_existing = False

for experiment in tqdm(os.listdir(log_dir)):
    if not os.path.isdir(os.path.join(log_dir, experiment)):
        continue

    for run in os.listdir(os.path.join(log_dir, experiment)):
        if not os.path.isdir(os.path.join(log_dir, experiment, run)):
            continue

        for file in os.listdir(os.path.join(log_dir, experiment, run)):
            if file.startswith("events.out.tfevents"):
                out_dir = os.path.join(output_dir, experiment, run)
                os.makedirs(out_dir, exist_ok=True)

                in_path = os.path.join(log_dir, experiment, run, file)
                
                save_scalar_data(in_path, out_dir, skip_existing)
print("Done.")
